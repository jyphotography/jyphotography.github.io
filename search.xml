<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[课后阅读1： Mastering Data Mining]]></title>
      <url>https://jyphotography.github.io/2016/10/26/Data-Mining-Reading-1/</url>
      <content type="html"><![CDATA[<h1 id="Chapter-1-Data-Mining-in-Context"><a href="#Chapter-1-Data-Mining-in-Context" class="headerlink" title="Chapter 1 Data Mining in Context"></a>Chapter 1 Data Mining in Context</h1><h2 id="What-is-Data-Mining"><a href="#What-is-Data-Mining" class="headerlink" title="What is Data Mining"></a>What is Data Mining</h2><p>Data mining is the process of exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful pattern and rules.–John Wiley</p>
<h2 id="What-Can-Data-Mining-DO"><a href="#What-Can-Data-Mining-DO" class="headerlink" title="What Can Data Mining DO?"></a>What Can Data Mining DO?</h2><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><p>examine the features of a newly presented object and assign to it a predefined class</p>
<h3 id="Estimation"><a href="#Estimation" class="headerlink" title="Estimation"></a>Estimation</h3><p>deal with continuously valued outcome</p>
<h3 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h3><p>Prediction cannot be checked about accuracy. We can only wait and see</p>
<h3 id="Affinity-Grouping"><a href="#Affinity-Grouping" class="headerlink" title="Affinity Grouping"></a>Affinity Grouping</h3><p>things go together (cross-selling opportunities)</p>
<h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><p>diverse group into similar subgroups</p>
<h3 id="Description-and-Visualization"><a href="#Description-and-Visualization" class="headerlink" title="Description and Visualization"></a>Description and Visualization</h3><p>data visualization</p>
<h2 id="The-Business-Context-for-Data-Mining"><a href="#The-Business-Context-for-Data-Mining" class="headerlink" title="The Business Context for Data Mining"></a>The Business Context for Data Mining</h2><ol>
<li>large quantities of data</li>
<li>worth learning</li>
</ol>
<h3 id="Research-Tool"><a href="#Research-Tool" class="headerlink" title="Research Tool"></a>Research Tool</h3><h3 id="Process-Improvement"><a href="#Process-Improvement" class="headerlink" title="Process Improvement"></a>Process Improvement</h3><h3 id="Marketing"><a href="#Marketing" class="headerlink" title="Marketing"></a>Marketing</h3><h3 id="Customer-Relationship-Management"><a href="#Customer-Relationship-Management" class="headerlink" title="Customer Relationship Management"></a>Customer Relationship Management</h3><h2 id="The-Technical-Context-for-Data-Mining"><a href="#The-Technical-Context-for-Data-Mining" class="headerlink" title="The Technical Context for Data Mining"></a>The Technical Context for Data Mining</h2><ol>
<li>Algorithms</li>
<li>Data</li>
<li>Modeling practices</li>
</ol>
<h3 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h3><p>Neural network<br>Decision Trees</p>
<h3 id="Statistics"><a href="#Statistics" class="headerlink" title="Statistics"></a>Statistics</h3><h3 id="Decision-Support"><a href="#Decision-Support" class="headerlink" title="Decision Support"></a>Decision Support</h3><h4 id="Data-Warehouse"><a href="#Data-Warehouse" class="headerlink" title="Data Warehouse"></a>Data Warehouse</h4><h4 id="OLAP"><a href="#OLAP" class="headerlink" title="OLAP"></a>OLAP</h4><p>Decision Support Fusion</p>
<h3 id="Computer-Technology"><a href="#Computer-Technology" class="headerlink" title="Computer Technology"></a>Computer Technology</h3><h2 id="The-Societal-Context-for-Data-Mining"><a href="#The-Societal-Context-for-Data-Mining" class="headerlink" title="The Societal Context for Data Mining"></a>The Societal Context for Data Mining</h2><h1 id="Chapter-2-Why-Master-the-Art"><a href="#Chapter-2-Why-Master-the-Art" class="headerlink" title="Chapter 2 Why Master the Art?"></a>Chapter 2 Why Master the Art?</h1><h2 id="Four-Approaches-to-Data-Mining"><a href="#Four-Approaches-to-Data-Mining" class="headerlink" title="Four Approaches to Data Mining"></a>Four Approaches to Data Mining</h2><h3 id="Purchasing-Scores"><a href="#Purchasing-Scores" class="headerlink" title="Purchasing Scores"></a>Purchasing Scores</h3><h3 id="Purchasing-Software"><a href="#Purchasing-Software" class="headerlink" title="Purchasing Software"></a>Purchasing Software</h3><h3 id="Purchasing-Models"><a href="#Purchasing-Models" class="headerlink" title="Purchasing Models"></a>Purchasing Models</h3><p>neural net models for predicting fraud in credit, product Falcon. Concern-false positive-innocent people<br>vertical application</p>
<h3 id="Purchasing-Model-Building-Software"><a href="#Purchasing-Model-Building-Software" class="headerlink" title="Purchasing Model-Building Software"></a>Purchasing Model-Building Software</h3><p>Quadstone Decision house</p>
<h4 id="what-tools-can-and-cannot-automate"><a href="#what-tools-can-and-cannot-automate" class="headerlink" title="what tools can and cannot automate"></a>what tools can and cannot automate</h4><p>assumption is important</p>
<h2 id="Hiring-Outside-Experts"><a href="#Hiring-Outside-Experts" class="headerlink" title="Hiring Outside Experts"></a>Hiring Outside Experts</h2><ol>
<li>one time vs on-going</li>
<li>source of data</li>
<li>how be employed</li>
<li>availability and skill level</li>
</ol>
<h2 id="Lessons-Learned"><a href="#Lessons-Learned" class="headerlink" title="Lessons Learned"></a>Lessons Learned</h2><ol>
<li>understand business problem</li>
<li>select relevant data</li>
<li>transform data</li>
<li>interpret result</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[第二章 如何找寻可靠的模型]]></title>
      <url>https://jyphotography.github.io/2016/10/26/Data-Mining-II/</url>
      <content type="html"><![CDATA[<h1 id="第二章-如何找寻可靠的模型"><a href="#第二章-如何找寻可靠的模型" class="headerlink" title="第二章 如何找寻可靠的模型"></a>第二章 如何找寻可靠的模型</h1><h3 id="I-数据类型"><a href="#I-数据类型" class="headerlink" title="I. 数据类型"></a>I. 数据类型</h3><ol>
<li>数字型</li>
<li>类型</li>
<li>顺序型</li>
</ol>
<hr>
<h3 id="II-基本模型"><a href="#II-基本模型" class="headerlink" title="II. 基本模型"></a>II. 基本模型</h3><h4 id="预测分析模型"><a href="#预测分析模型" class="headerlink" title="预测分析模型"></a>预测分析模型</h4><h5 id="回归模型-Regression"><a href="#回归模型-Regression" class="headerlink" title="回归模型(Regression)"></a>回归模型(Regression)</h5><ol>
<li>输入-数字型， 输出-数字型</li>
<li>方法： 线性， 非线性， 多重， 无变量， 神经网络<br><img src="/media/14774559742028.jpg" alt="-w301"></li>
</ol>
<h5 id="分类模型-Classification"><a href="#分类模型-Classification" class="headerlink" title="分类模型(Classification)"></a>分类模型(Classification)</h5><ol>
<li>输入-标记，数字，综合， 输出-标记<br><img src="/media/14774561356759.jpg" alt="-w281"></li>
</ol>
<h4 id="2-描述分析模型"><a href="#2-描述分析模型" class="headerlink" title="2. 描述分析模型"></a>2. 描述分析模型</h4><h5 id="聚类模型-Clustering"><a href="#聚类模型-Clustering" class="headerlink" title="聚类模型(Clustering)"></a>聚类模型(Clustering)</h5><ol>
<li>输入-标记，数字，综合， 输出-无<pre><code>![-w311](/media/14774565022310.jpg)
</code></pre><img src="/media/14774565177615.jpg" alt="-w300"></li>
</ol>
<h5 id="核密度估计-Density-Estimation"><a href="#核密度估计-Density-Estimation" class="headerlink" title="核密度估计(Density Estimation)"></a>核密度估计(Density Estimation)</h5><ol>
<li>输入-标记，数字，综合， 输出-无<br><img src="/media/14774578391136.jpg" alt="-w262"></li>
</ol>
<h5 id="构造学习-Structural-Learning"><a href="#构造学习-Structural-Learning" class="headerlink" title="构造学习(Structural Learning)"></a>构造学习(Structural Learning)</h5><p><img src="/media/14774570120650.jpg" alt="-w343"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/media/14774570628957.jpg" alt="-w311"></p>
<hr>
<h3 id="III-学习的类型"><a href="#III-学习的类型" class="headerlink" title="III.学习的类型"></a>III.学习的类型</h3><h4 id="监督学习-Supervised-Learning"><a href="#监督学习-Supervised-Learning" class="headerlink" title="监督学习(Supervised Learning)"></a>监督学习(Supervised Learning)</h4><p>适用于回归， 分类<br><img src="/media/14774583074116.jpg" alt="-w298"></p>
<h4 id="非监督学习-Unsupervised-Learning"><a href="#非监督学习-Unsupervised-Learning" class="headerlink" title="非监督学习(Unsupervised Learning)"></a>非监督学习(Unsupervised Learning)</h4><p>适用于聚类， 核密度估计<br><img src="/media/14774583249554.jpg" alt="-w297"></p>
<h4 id="半监督学习-Semi-supervised-Learning"><a href="#半监督学习-Semi-supervised-Learning" class="headerlink" title="半监督学习(Semi-supervised Learning)"></a>半监督学习(Semi-supervised Learning)</h4><p>数据有些有输出值</p>
<h4 id="增强学习-Reinforcement-Learning"><a href="#增强学习-Reinforcement-Learning" class="headerlink" title="增强学习(Reinforcement Learning)"></a>增强学习(Reinforcement Learning)</h4><p>适用于优化和控制问题<br><img src="/media/14774583410906.jpg" alt="-w294"></p>
<h3 id="模型架构类型"><a href="#模型架构类型" class="headerlink" title="模型架构类型"></a>模型架构类型</h3><p>1.变量模型<br>    假定：模型符合一定的函数形式<br>2.非变量模型(memory-based)<br>    记住所有训练集</p>
<h2 id="正规化（Generalization）"><a href="#正规化（Generalization）" class="headerlink" title="正规化（Generalization）"></a>正规化（Generalization）</h2><h4 id="如何数量化正规化结果？"><a href="#如何数量化正规化结果？" class="headerlink" title="如何数量化正规化结果？"></a>如何数量化正规化结果？</h4><p>留一些测试数据<br>根据测试数据预测模型拟合度</p>
<h4 id="正规化曲线"><a href="#正规化曲线" class="headerlink" title="正规化曲线"></a>正规化曲线</h4><p><img src="/media/14774882944364.jpg" alt="-w308"><br>如果什么都没学到，这张图记住就好。<br>古话说：过犹不及。你模型训练的太好，在实际使用中效果会没有什么用</p>
<h2 id="衡量模型正确性参数"><a href="#衡量模型正确性参数" class="headerlink" title="衡量模型正确性参数"></a>衡量模型正确性参数</h2><h4 id="预测误差（Prediction-Error"><a href="#预测误差（Prediction-Error" class="headerlink" title="预测误差（Prediction Error)"></a>预测误差（Prediction Error)</h4><p><img src="/media/14774887239335.jpg" alt="-w211"><br><img src="/media/14774887380989.jpg" alt=""><br>SSE 最简单粗暴<br>MSE 可以或略outlier因为取得是平均<br>RMSE 可以了解不同模型的离散程度<br>MAE 因为取绝对值，可以衡量平均误差大小</p>
<h4 id="如何找到合适的模型复杂度"><a href="#如何找到合适的模型复杂度" class="headerlink" title="如何找到合适的模型复杂度"></a>如何找到合适的模型复杂度</h4><ol>
<li>最简单：常量 y = b</li>
<li>线性回归(Linear Regression)</li>
<li>二次回归(Quadratic Regression)</li>
<li>多项回归(Polynomial Regression)</li>
</ol>
<p>并不是越复杂越好，因为会过拟合(over-fit)</p>
<h2 id="如何避免过拟合"><a href="#如何避免过拟合" class="headerlink" title="如何避免过拟合"></a>如何避免过拟合</h2><h4 id="检查并设置-Test-amp-Set"><a href="#检查并设置-Test-amp-Set" class="headerlink" title="检查并设置(Test&amp;Set)"></a>检查并设置(Test&amp;Set)</h4><ol>
<li>随机数据点</li>
<li>把数据分成两块：训练， 验证</li>
</ol>
<p><em>需要考虑怎么分？</em></p>
<ol>
<li>training set中样本数量必须够多，一般至少大于总样本数的50%。</li>
<li>两组子集必须从完整集合中均匀取样</li>
</ol>
<h4 id="交叉验证（Leave-One-Out-Cross-Validation"><a href="#交叉验证（Leave-One-Out-Cross-Validation" class="headerlink" title="交叉验证（Leave-One-Out Cross Validation)"></a>交叉验证（Leave-One-Out Cross Validation)</h4><ol>
<li>每个样本单独作为验证集</li>
<li>其余的N-1个样本作为训练集</li>
<li>循环之前的过程</li>
<li>选一个指标然后把所有模型结果放在一起比较  </li>
</ol>
<p><em>好处：</em></p>
<ol>
<li>每一回合中几乎所有的样本皆用于训练模型,因此最接近原始样本的分布</li>
<li>实验过程中没有随机因素会影响实验数据,确保实验过程是可以被复制的</li>
</ol>
<h4 id="K组验证-K-fold-Cross-Validation"><a href="#K组验证-K-fold-Cross-Validation" class="headerlink" title="K组验证(K-fold Cross Validation)"></a>K组验证(K-fold Cross Validation)</h4><ol>
<li>将原始数据随机分成K组（一般均分）</li>
<li>将每个子集数据分别做一次验证集</li>
<li>其余的K-1组子集数据作为训练集</li>
<li>加总结果</li>
</ol>
<h4 id="现实使用"><a href="#现实使用" class="headerlink" title="现实使用"></a>现实使用</h4><ol>
<li>M中模型和变量</li>
<li>使用同样的交叉检验</li>
<li>发现最好的模型</li>
<li>使用所有数据完成最终模型</li>
</ol>
<h4 id="复习"><a href="#复习" class="headerlink" title="复习"></a>复习</h4><p><strong>True or False</strong></p>
<ol>
<li>In 10-fold Cross-Validation, we are splitting data into 10 disjoint subsets and use each of them for testing exactly once.</li>
<li>In 10-fold Cross-Validation, we independently build 10 models using training subsets of data, and select for deployment the one that performs best on the testing subset of data.</li>
<li>We use 10-fold Cross-Validation to empirically quantify the expected performance of different types of models and/or their alternative configurations.<br>As soon as we identify the most suitable model type and configuration, we can re-train it using all available data and then transition the result to practice.</li>
</ol>
<p>答案：</p>
<ol>
<li>True</li>
<li>False</li>
<li>True</li>
</ol>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><ol>
<li>用交叉检验发现好的模型</li>
<li>模型选择（ROC）</li>
<li>其他模型测试方法</li>
</ol>
<h4 id="你应该知道"><a href="#你应该知道" class="headerlink" title="你应该知道"></a>你应该知道</h4><ol>
<li>数据类型</li>
<li>模型类型和区别</li>
<li>基本模型学习</li>
<li>如何衡量预测准确性</li>
<li>为什么偏好正规化的模型</li>
<li>什么是过拟合，如何规避</li>
<li>交叉检验如何使用</li>
</ol>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[第一章 数据挖掘]]></title>
      <url>https://jyphotography.github.io/2016/10/25/Data-Mining-I/</url>
      <content type="html"><![CDATA[<h1 id="第一章-数据挖掘"><a href="#第一章-数据挖掘" class="headerlink" title="第一章 数据挖掘"></a>第一章 数据挖掘</h1><h3 id="I-什么是数据挖掘"><a href="#I-什么是数据挖掘" class="headerlink" title="I. 什么是数据挖掘"></a>I. 什么是数据挖掘</h3><ol>
<li>数据中寻找规律</li>
<li>数据中寻找关系</li>
<li>数据中提取信息  </li>
</ol>
<hr>
<h3 id="II-主要因数"><a href="#II-主要因数" class="headerlink" title="II. 主要因数"></a>II. 主要因数</h3><ol>
<li>数据的可得到性</li>
<li>运算能力</li>
<li>统计学</li>
<li>人工智能／机器学习</li>
<li><strong>对信息的需求 （主要动机）</strong></li>
<li>公司仪器</li>
</ol>
<hr>
<h3 id="III-数据挖掘周期"><a href="#III-数据挖掘周期" class="headerlink" title="III. 数据挖掘周期"></a>III. 数据挖掘周期</h3><p><img src="/media/14774550278762.jpg" alt="-m426"></p>
<hr>
<h3 id="IV-分析周期"><a href="#IV-分析周期" class="headerlink" title="IV. 分析周期"></a>IV. 分析周期</h3><p><img src="/media/14774550921846.jpg" alt="-m490"></p>
]]></content>
    </entry>
    
  
  
</search>
